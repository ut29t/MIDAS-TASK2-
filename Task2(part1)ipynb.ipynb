{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task2(part1)ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "972E70HW1Bde"
      },
      "source": [
        "**In this section we imported various libraries for the building of the cnn model. We used the tensorflow and the keras as our framework.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdKmC4lC0VZm"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_0H_bjq14vM"
      },
      "source": [
        "In this section the training data is uploaded from the drive into the colab.\n",
        "The preprocessing is an important step for any training process, so the preprocessing is done using the ImageDataGenerator like( rescaling, rotation and fliping of the image dataset)\n",
        "\n",
        "The target image is reduced from(1200 900) to (224 224) (many set of dimensions were used to enhance performance) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmSmp4-_XIh9",
        "outputId": "131c9d25-b171-4f00-f394-d02069d9c1b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_data='/content/drive/MyDrive/MIDAS/train'\n",
        "\n",
        "\n",
        "train_gen=ImageDataGenerator(rescale=1./255,  shear_range=0.2, zoom_range=0.2,\n",
        "                             horizontal_flip=True, vertical_flip=True)\n",
        "\n",
        "train_generator=train_gen.flow_from_directory(train_data,color_mode='grayscale',target_size=(224,224),\n",
        "                                              batch_size=64,class_mode='categorical',shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Found 2480 images belonging to 62 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy4JRo254Hh7"
      },
      "source": [
        "This is the Architecture of the cnn model\n",
        "Summary of the model is displayed below explaining about various types of the layers used in the model builading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrH8HCFbYFZ4",
        "outputId": "f6f83d42-db40-4ef7-94e9-3ff9b375db15"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  \n",
        "  layers.Conv2D(filters=32,padding=\"same\",kernel_size=3,activation='relu',input_shape=[224,224,1]),\n",
        "  layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "  layers.Conv2D(filters=32,padding=\"same\",kernel_size=3,activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "  layers.Conv2D(filters=64,padding=\"same\",kernel_size=3,activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(units=128, activation='relu'),\n",
        "  layers.Dense(units=62, activation='softmax'),\n",
        "  \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 112, 112, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 62)                7998      \n",
            "=================================================================\n",
            "Total params: 6,458,718\n",
            "Trainable params: 6,458,718\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYCbkAjmaS9H"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma3-LiNXaepa",
        "outputId": "4542674a-903c-4bf3-8275-33137ed8f653"
      },
      "source": [
        "epochs=50\n",
        "history = model.fit(train_generator,epochs=epochs)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "39/39 [==============================] - 512s 13s/step - loss: 4.1995 - accuracy: 0.0157\n",
            "Epoch 2/50\n",
            "39/39 [==============================] - 181s 5s/step - loss: 4.0906 - accuracy: 0.0207\n",
            "Epoch 3/50\n",
            "39/39 [==============================] - 177s 4s/step - loss: 3.8336 - accuracy: 0.0724\n",
            "Epoch 4/50\n",
            "39/39 [==============================] - 173s 4s/step - loss: 3.3810 - accuracy: 0.1516\n",
            "Epoch 5/50\n",
            "39/39 [==============================] - 169s 4s/step - loss: 2.9064 - accuracy: 0.2489\n",
            "Epoch 6/50\n",
            "39/39 [==============================] - 167s 4s/step - loss: 2.6336 - accuracy: 0.2853\n",
            "Epoch 7/50\n",
            "39/39 [==============================] - 165s 4s/step - loss: 2.4583 - accuracy: 0.3194\n",
            "Epoch 8/50\n",
            "39/39 [==============================] - 163s 4s/step - loss: 2.2803 - accuracy: 0.3598\n",
            "Epoch 9/50\n",
            "39/39 [==============================] - 169s 4s/step - loss: 2.1103 - accuracy: 0.3921\n",
            "Epoch 10/50\n",
            "39/39 [==============================] - 164s 4s/step - loss: 1.9128 - accuracy: 0.4519\n",
            "Epoch 11/50\n",
            "39/39 [==============================] - 165s 4s/step - loss: 1.7910 - accuracy: 0.4974\n",
            "Epoch 12/50\n",
            "39/39 [==============================] - 164s 4s/step - loss: 1.7025 - accuracy: 0.5176\n",
            "Epoch 13/50\n",
            "39/39 [==============================] - 164s 4s/step - loss: 1.6760 - accuracy: 0.5141\n",
            "Epoch 14/50\n",
            "39/39 [==============================] - 164s 4s/step - loss: 1.5105 - accuracy: 0.5598\n",
            "Epoch 15/50\n",
            "39/39 [==============================] - 162s 4s/step - loss: 1.4490 - accuracy: 0.5758\n",
            "Epoch 16/50\n",
            "39/39 [==============================] - 162s 4s/step - loss: 1.3873 - accuracy: 0.5861\n",
            "Epoch 17/50\n",
            "39/39 [==============================] - 162s 4s/step - loss: 1.3314 - accuracy: 0.6164\n",
            "Epoch 18/50\n",
            "39/39 [==============================] - 162s 4s/step - loss: 1.2293 - accuracy: 0.6299\n",
            "Epoch 19/50\n",
            "39/39 [==============================] - 161s 4s/step - loss: 1.1834 - accuracy: 0.6499\n",
            "Epoch 20/50\n",
            "39/39 [==============================] - 162s 4s/step - loss: 1.1335 - accuracy: 0.6515\n",
            "Epoch 21/50\n",
            "39/39 [==============================] - 161s 4s/step - loss: 1.1325 - accuracy: 0.6658\n",
            "Epoch 22/50\n",
            "39/39 [==============================] - 162s 4s/step - loss: 1.0452 - accuracy: 0.6916\n",
            "Epoch 23/50\n",
            "39/39 [==============================] - 163s 4s/step - loss: 1.0257 - accuracy: 0.6933\n",
            "Epoch 24/50\n",
            "39/39 [==============================] - 163s 4s/step - loss: 1.0063 - accuracy: 0.7106\n",
            "Epoch 25/50\n",
            "39/39 [==============================] - 164s 4s/step - loss: 0.8842 - accuracy: 0.7348\n",
            "Epoch 26/50\n",
            "39/39 [==============================] - 168s 4s/step - loss: 0.8791 - accuracy: 0.7360\n",
            "Epoch 27/50\n",
            "39/39 [==============================] - 165s 4s/step - loss: 0.8075 - accuracy: 0.7476\n",
            "Epoch 28/50\n",
            "39/39 [==============================] - 163s 4s/step - loss: 0.7543 - accuracy: 0.7518\n",
            "Epoch 29/50\n",
            "39/39 [==============================] - 162s 4s/step - loss: 0.8144 - accuracy: 0.7519\n",
            "Epoch 30/50\n",
            "39/39 [==============================] - 168s 4s/step - loss: 0.7500 - accuracy: 0.7802\n",
            "Epoch 31/50\n",
            "39/39 [==============================] - 169s 4s/step - loss: 0.7375 - accuracy: 0.7727\n",
            "Epoch 32/50\n",
            "39/39 [==============================] - 171s 4s/step - loss: 0.7134 - accuracy: 0.7828\n",
            "Epoch 33/50\n",
            "39/39 [==============================] - 172s 4s/step - loss: 0.6535 - accuracy: 0.7957\n",
            "Epoch 34/50\n",
            "39/39 [==============================] - 172s 4s/step - loss: 0.5851 - accuracy: 0.8182\n",
            "Epoch 35/50\n",
            "39/39 [==============================] - 173s 4s/step - loss: 0.5866 - accuracy: 0.8165\n",
            "Epoch 36/50\n",
            "39/39 [==============================] - 171s 4s/step - loss: 0.5553 - accuracy: 0.8236\n",
            "Epoch 37/50\n",
            "39/39 [==============================] - 169s 4s/step - loss: 0.5276 - accuracy: 0.8357\n",
            "Epoch 38/50\n",
            "39/39 [==============================] - 170s 4s/step - loss: 0.5483 - accuracy: 0.8352\n",
            "Epoch 39/50\n",
            "39/39 [==============================] - 168s 4s/step - loss: 0.5279 - accuracy: 0.8327\n",
            "Epoch 40/50\n",
            "39/39 [==============================] - 169s 4s/step - loss: 0.5017 - accuracy: 0.8435\n",
            "Epoch 41/50\n",
            "39/39 [==============================] - 174s 4s/step - loss: 0.4231 - accuracy: 0.8553\n",
            "Epoch 42/50\n",
            "39/39 [==============================] - 171s 4s/step - loss: 0.5128 - accuracy: 0.8397\n",
            "Epoch 43/50\n",
            "39/39 [==============================] - 166s 4s/step - loss: 0.4345 - accuracy: 0.8508\n",
            "Epoch 44/50\n",
            "39/39 [==============================] - 163s 4s/step - loss: 0.4070 - accuracy: 0.8714\n",
            "Epoch 45/50\n",
            "39/39 [==============================] - 163s 4s/step - loss: 0.4986 - accuracy: 0.8409\n",
            "Epoch 46/50\n",
            "39/39 [==============================] - 163s 4s/step - loss: 0.4199 - accuracy: 0.8517\n",
            "Epoch 47/50\n",
            "39/39 [==============================] - 162s 4s/step - loss: 0.4065 - accuracy: 0.8688\n",
            "Epoch 48/50\n",
            "39/39 [==============================] - 163s 4s/step - loss: 0.3916 - accuracy: 0.8835\n",
            "Epoch 49/50\n",
            "39/39 [==============================] - 163s 4s/step - loss: 0.3508 - accuracy: 0.8843\n",
            "Epoch 50/50\n",
            "39/39 [==============================] - 164s 4s/step - loss: 0.3786 - accuracy: 0.8758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otjq5QMV58rR"
      },
      "source": [
        "As as you can see the final accuracy of the model has reached to upto 87% and loss of the model is also less as compared to earlier epochs."
      ]
    }
  ]
}