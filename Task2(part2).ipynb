{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task2(part2)",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QsUB8EjsqxC"
      },
      "source": [
        "In this section we just imported import libraries, which are necessary for the building of the model.These libraries ,ainly include numpy, matplotlib and frameworks like keras and tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IlppMBfIhGj"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ODapBm3tKbZ"
      },
      "source": [
        "This section shows the dataset(containing images(0-9)) each having the dimension of(1200*900) being uploaded to the colab from the drive.\n",
        "\n",
        "Preprocessing of the dataset-ImageDataGenertaor is used for the preprocessing of the image dataset.It contains various parameters like resacling, rotation, fliping etc.\n",
        "The dimensions of the image were brought to(224,224) and then trained.\n",
        "It was seen that on reducing the size to great extent(32,32), the accuracy of the model was increasing, but there was a doubt of overfitting of the model, so preferred target size(224,224).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHDr7epSIqmW",
        "outputId": "3619ef97-7276-4f5c-e4c8-cbb18d0e0fa1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_data='/content/drive/MyDrive/MIDAS/0-9'\n",
        "\n",
        "\n",
        "train_gen=ImageDataGenerator(rescale=1./255, rotation_range=0.3, shear_range=0.3, zoom_range=0.3,\n",
        "                             horizontal_flip=True, vertical_flip=True)\n",
        "\n",
        "train_generator=train_gen.flow_from_directory(train_data,color_mode='grayscale',target_size=(224,224),\n",
        "                                              batch_size=16,class_mode='categorical',shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 400 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjW9X87UxYnP"
      },
      "source": [
        "This shows the architecture used for the training purpose, the summary of the model is displayed below\n",
        "Basically 3(convolutional nad max pooling) are used and activation function is (ReLU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1nA5ubTItdx",
        "outputId": "bab25c5d-8ac1-446f-b315-dab5446bd539"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  \n",
        "  layers.Conv2D(filters=32,padding=\"same\",kernel_size=3,activation='relu',input_shape=[224,224,1]),\n",
        "  layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "  layers.Conv2D(filters=32,padding=\"same\",kernel_size=3,activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "  layers.Conv2D(filters=64,padding=\"same\",kernel_size=3,activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(units=128, activation='relu'),\n",
        "  layers.Dense(units=10, activation='softmax'),\n",
        "  \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 224, 224, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 112, 112, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 56, 56, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 6,452,010\n",
            "Trainable params: 6,452,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtydSHHwI4Qw"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM_XyfF1z2oq"
      },
      "source": [
        "It is seen that the loss below is decreasing and the accuracy of the model is increasing, if the number of the epochs are increased the accuracy would further increase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQus8VHoI5h3",
        "outputId": "4beafb9c-a10d-4350-9652-d68d29b555ff"
      },
      "source": [
        "epochs=10\n",
        "history = model.fit(train_generator,epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 71s 3s/step - loss: 2.7917 - accuracy: 0.0680\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 2.2776 - accuracy: 0.1445\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 7s 275ms/step - loss: 2.0919 - accuracy: 0.2360\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 7s 273ms/step - loss: 1.9588 - accuracy: 0.2812\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 7s 266ms/step - loss: 1.5567 - accuracy: 0.4878\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 7s 268ms/step - loss: 1.5289 - accuracy: 0.4846\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 1.2722 - accuracy: 0.5681\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 1.3635 - accuracy: 0.5526\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 1.1618 - accuracy: 0.6185\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 1.1903 - accuracy: 0.6112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PksUyh9XmJu"
      },
      "source": [
        "This section of the code, we use the pretrained network on the MNIST dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMdJbx4VXlJW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "mnist=tf.keras.datasets.mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWvQrgs_0YzA"
      },
      "source": [
        "This is the standard train and test split for the mnist dataset with their respective labels.\n",
        "\n",
        "We have directly loaded the mnist dataset in the colab and trained it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ADnM8k6ZSeH"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ZScT-9j7ZdlL",
        "outputId": "868bb2c5-9d11-48b7-fac2-78b4b528de01"
      },
      "source": [
        "plt.imshow(x_test[0],cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc107453ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAM3ElEQVR4nO3dXahc9bnH8d/vpCmI6UXiS9ik0bTBC8tBEo1BSCxbQktOvIjFIM1FyYHi7kWUFkuo2It4WaQv1JvALkrTkmMJpGoQscmJxVDU4o5Es2NIjCGaxLxYIjQRJMY+vdjLso0za8ZZa2ZN8nw/sJmZ9cya9bDMz7VmvczfESEAV77/aroBAINB2IEkCDuQBGEHkiDsQBJfGeTCbHPoH+iziHCr6ZW27LZX2j5o+7Dth6t8FoD+cq/n2W3PkHRI0nckHZf0mqS1EfFWyTxs2YE+68eWfamkwxFxJCIuSPqTpNUVPg9AH1UJ+zxJx6a9Pl5M+xzbY7YnbE9UWBaAivp+gC4ixiWNS+zGA02qsmU/IWn+tNdfL6YBGEJVwv6apJtsf8P2VyV9X9L2etoCULeed+Mj4qLtByT9RdIMSU9GxP7aOgNQq55PvfW0ML6zA33Xl4tqAFw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9Dw+uyTZPirpnKRPJV2MiCV1NAWgfpXCXrgrIv5Rw+cA6CN244EkqoY9JO2wvcf2WKs32B6zPWF7ouKyAFTgiOh9ZnteRJywfb2knZIejIjdJe/vfWEAuhIRbjW90pY9Ik4Uj2ckPS1paZXPA9A/PYfd9tW2v/bZc0nflTRZV2MA6lXlaPxcSU/b/uxz/i8iXqilKwC1q/Sd/UsvjO/sQN/15Ts7gMsHYQeSIOxAEoQdSIKwA0nUcSNMCmvWrGlbu//++0vnff/990vrH3/8cWl9y5YtpfVTp061rR0+fLh0XuTBlh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuCuty4dOXKkbW3BggWDa6SFc+fOta3t379/gJ0Ml+PHj7etPfbYY6XzTkxcvr+ixl1vQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AE97N3qeye9VtuuaV03gMHDpTWb7755tL6rbfeWlofHR1tW7vjjjtK5z127Fhpff78+aX1Ki5evFha/+CDD0rrIyMjPS/7vffeK61fzufZ22HLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcD/7FWD27Nlta4sWLSqdd8+ePaX122+/vaeeutHp9/IPHTpUWu90/cKcOXPa1tavX18676ZNm0rrw6zn+9ltP2n7jO3JadPm2N5p++3isf2/NgBDoZvd+N9LWnnJtIcl7YqImyTtKl4DGGIdwx4RuyWdvWTyakmbi+ebJd1Tc18AatbrtfFzI+Jk8fyUpLnt3mh7TNJYj8sBUJPKN8JERJQdeIuIcUnjEgfogCb1eurttO0RSSoez9TXEoB+6DXs2yWtK56vk/RsPe0A6JeO59ltPyVpVNK1kk5L2ijpGUlbJd0g6V1J90XEpQfxWn0Wu/Ho2r333lta37p1a2l9cnKybe2uu+4qnffs2Y7/nIdWu/PsHb+zR8TaNqUVlToCMFBcLgskQdiBJAg7kARhB5Ig7EAS3OKKxlx//fWl9X379lWaf82aNW1r27ZtK533csaQzUByhB1IgrADSRB2IAnCDiRB2IEkCDuQBEM2ozGdfs75uuuuK61/+OGHpfWDBw9+6Z6uZGzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ7mdHXy1btqxt7cUXXyydd+bMmaX10dHR0vru3btL61cq7mcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSS4nx19tWrVqra1TufRd+3aVVp/5ZVXeuopq45bdttP2j5je3LatEdtn7C9t/hr/18UwFDoZjf+95JWtpj+m4hYVPw9X29bAOrWMewRsVvS2QH0AqCPqhyge8D2m8Vu/ux2b7I9ZnvC9kSFZQGoqNewb5K0UNIiSScl/ardGyNiPCKWRMSSHpcFoAY9hT0iTkfEpxHxL0m/k7S03rYA1K2nsNsemfbye5Im270XwHDoeJ7d9lOSRiVda/u4pI2SRm0vkhSSjkr6UR97xBC76qqrSusrV7Y6kTPlwoULpfNu3LixtP7JJ5+U1vF5HcMeEWtbTH6iD70A6CMulwWSIOxAEoQdSIKwA0kQdiAJbnFFJRs2bCitL168uG3thRdeKJ335Zdf7qkntMaWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYMhmlLr77rtL688880xp/aOPPmpbK7v9VZJeffXV0jpaY8hmIDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC+9mTu+aaa0rrjz/+eGl9xowZpfXnn28/5ifn0QeLLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMH97Fe4TufBO53rvu2220rr77zzTmm97J71TvOiNz3fz257vu2/2n7L9n7bPy6mz7G90/bbxePsupsGUJ9uduMvSvppRHxL0h2S1tv+lqSHJe2KiJsk7SpeAxhSHcMeEScj4vXi+TlJByTNk7Ra0ubibZsl3dOvJgFU96Wujbe9QNJiSX+XNDciThalU5LmtplnTNJY7y0CqEPXR+Ntz5K0TdJPIuKf02sxdZSv5cG3iBiPiCURsaRSpwAq6SrstmdqKuhbIuLPxeTTtkeK+oikM/1pEUAdOu7G27akJyQdiIhfTyttl7RO0i+Kx2f70iEqWbhwYWm906m1Th566KHSOqfXhkc339mXSfqBpH229xbTHtFUyLfa/qGkdyXd158WAdShY9gj4m+SWp6kl7Si3nYA9AuXywJJEHYgCcIOJEHYgSQIO5AEPyV9Bbjxxhvb1nbs2FHpszds2FBaf+655yp9PgaHLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59ivA2Fj7X/264YYbKn32Sy+9VFof5E+Roxq27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOfZLwPLly8vrT/44IMD6gSXM7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEN+Ozz5f0B0lzJYWk8Yj4re1HJd0v6YPirY9ExPP9ajSzO++8s7Q+a9asnj+70/jp58+f7/mzMVy6uajmoqSfRsTrtr8maY/tnUXtNxHxy/61B6Au3YzPflLSyeL5OdsHJM3rd2MA6vWlvrPbXiBpsaS/F5MesP2m7Sdtz24zz5jtCdsTlToFUEnXYbc9S9I2ST+JiH9K2iRpoaRFmtry/6rVfBExHhFLImJJDf0C6FFXYbc9U1NB3xIRf5akiDgdEZ9GxL8k/U7S0v61CaCqjmG3bUlPSDoQEb+eNn1k2tu+J2my/vYA1KWbo/HLJP1A0j7be4tpj0haa3uRpk7HHZX0o750iEreeOON0vqKFStK62fPnq2zHTSom6Pxf5PkFiXOqQOXEa6gA5Ig7EAShB1IgrADSRB2IAnCDiThQQ65a5vxfYE+i4hWp8rZsgNZEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoMesvkfkt6d9vraYtowGtbehrUvid56VWdvN7YrDPSimi8s3J4Y1t+mG9behrUvid56Naje2I0HkiDsQBJNh3284eWXGdbehrUvid56NZDeGv3ODmBwmt6yAxgQwg4k0UjYba+0fdD2YdsPN9FDO7aP2t5ne2/T49MVY+idsT05bdoc2zttv108thxjr6HeHrV9olh3e22vaqi3+bb/avst2/tt/7iY3ui6K+lrIOtt4N/Zbc+QdEjSdyQdl/SapLUR8dZAG2nD9lFJSyKi8QswbH9b0nlJf4iI/y6mPSbpbET8ovgf5eyI+NmQ9PaopPNND+NdjFY0Mn2YcUn3SPpfNbjuSvq6TwNYb01s2ZdKOhwRRyLigqQ/SVrdQB9DLyJ2S7p0SJbVkjYXzzdr6h/LwLXpbShExMmIeL14fk7SZ8OMN7ruSvoaiCbCPk/SsWmvj2u4xnsPSTts77E91nQzLcyNiJPF81OS5jbZTAsdh/EepEuGGR+addfL8OdVcYDui5ZHxK2S/kfS+mJ3dSjF1HewYTp32tUw3oPSYpjx/2hy3fU6/HlVTYT9hKT5015/vZg2FCLiRPF4RtLTGr6hqE9/NoJu8Xim4X7+Y5iG8W41zLiGYN01Ofx5E2F/TdJNtr9h+6uSvi9pewN9fIHtq4sDJ7J9taTvaviGot4uaV3xfJ2kZxvs5XOGZRjvdsOMq+F11/jw5xEx8D9JqzR1RP4dST9vooc2fX1T0hvF3/6me5P0lKZ26z7R1LGNH0q6RtIuSW9L+n9Jc4aotz9K2ifpTU0Fa6Sh3pZrahf9TUl7i79VTa+7kr4Gst64XBZIggN0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEvwEvYRv57rmVLgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z74-BKv5w-RY",
        "outputId": "89f3e73c-7db0-46c9-9011-b8ca4d046af5"
      },
      "source": [
        " x_train= x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_train/=255\n",
        "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
        "x_test = x_test.astype('float32')\n",
        "x_test/=255\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9pObZ_0449"
      },
      "source": [
        "Since we are using the same architecture for the MNIST dataset to identify the difference (of same model using different datasets)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAJnADyYZi_1",
        "outputId": "f94f28c9-ee2c-4e6f-d86b-f99d785a4272"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  \n",
        "  layers.Conv2D(filters=32,padding=\"same\",kernel_size=3,activation='relu',input_shape=[28,28,1]),\n",
        "  layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "  layers.Conv2D(filters=32,padding=\"same\",kernel_size=3,activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "  layers.Conv2D(filters=64,padding=\"same\",kernel_size=3,activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(units=128, activation='relu'),\n",
        "  layers.Dense(units=10, activation='softmax'),\n",
        "  \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_27 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 103,210\n",
            "Trainable params: 103,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE3bR5Ziffpl"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpYmC8qEmgHo",
        "outputId": "c58b289d-05e3-4380-d9e1-0a21a7ef64eb"
      },
      "source": [
        "epochs=10\n",
        "history = model.fit(x_train,y_train,epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 38s 3ms/step - loss: 0.3599 - accuracy: 0.8865\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0496 - accuracy: 0.9849\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0320 - accuracy: 0.9896\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0254 - accuracy: 0.9919\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0190 - accuracy: 0.9942\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0165 - accuracy: 0.9951\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0115 - accuracy: 0.9962\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0129 - accuracy: 0.9955\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0095 - accuracy: 0.9973\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0084 - accuracy: 0.9974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrQSUlgx3k0B"
      },
      "source": [
        "                                                               Comparison\n",
        "  Model1:\n",
        "  The original dataset used the images(1200*900)\n",
        "  the dataset was not refined or preprocessed,\n",
        "  due to which it took longer time for it to train and the accuracy is also low.\n",
        "\n",
        "  Model2:\n",
        "  MNIST is a refined dataset(28*28)\n",
        "  due to which it is easier to train.\n",
        "The convergence was also low and the accuracy was very high as compared to the Model1 for the same number of epochs."
      ]
    }
  ]
}